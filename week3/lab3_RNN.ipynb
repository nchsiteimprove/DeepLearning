{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%matplotlib nbagg\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "from data_generator import get_batch, print_valid_characters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks\n",
    "\n",
    "Recurrent neural networks are the natural choice for sequential data i.e. time series analysis, translation, speech recognition, biological sequence analysis etc. Recurrent neural networks works by recursively applying the same operation at each time step of the data sequence and having layers that pass information from previous time steps to the current. It can therefore naturally handle input of varying length. Recurrent networks are used for several prediction tasks including: sequence-to-class, sequence tagging, and sequence-to-sequence predictions.\n",
    "\n",
    "In this exercise we'll implement an Encoder-Decoder RNN build with the GRU unit. This type of models have shown impressive performance in Neural Machine Translation and Image Caption generation. \n",
    "\n",
    "For more in depth background material on RNNs please cf. [Supervised Sequence Labelling with Recurrent\n",
    "Neural Networks](https://www.cs.toronto.edu/~graves/preprint.pdf) by Alex Graves.\n",
    "\n",
    "We know that LSTMs and GRUs are difficult to understand. A very good non-mathematical introduction is [Chris Olahs blog](http://colah.github.io/posts/2015-08-Understanding-LSTMs/) (All the posts are nice and cover various topics within machine-learning)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder-Decoder\n",
    "In the encoder-decoder architecture, one RNN (blue) encodes the input and a second RNN (red) calculates the target values. One essential step is to let the encoder and decoder communicate. In the simplest approach you use the last hidden state of the encoder to initialize the decoder. Other approaches lets the decoder attend to different parts of the encoded input at different timesteps in the decoding process. \n",
    "\n",
    "<img src=\"files/enc-dec.png\", width=400>\n",
    "\n",
    "In our implementation we use a RNN with gated recurrent units (GRU) as encoder. We then use the last hidden state of the encoder ($h^{enc}_T$) as input to the decoder which is also a RNN with GRU units. \n",
    "\n",
    "### RNNs in Lasagne\n",
    "Lasagne has implementations of LSTM and GRU units. Both layers assume that the input from the layer below have the shape **(Batch_size, seq_len, num_features)**. In this excercise we will use the GRU unit since it only stores a single hidden value per neuron (LSTMs stores two) and is approximately twice as fast.\n",
    "\n",
    "As stated above we will implement an Encoder-Decoder model. The simplest way to do this is to encode the input sequence using the Encoder model. We will then use the last hidden state of the Encoder $h^{enc}_T$ as input to the decoder model, which then uses this information (simply a fixed length vector of numbers) to produce the targets. There is (at least) two ways to input $h^{enc}_T$ into the decoder\n",
    "\n",
    "1. Repeatly use $h^{enc}_T$ as input to the Decoder at each decode time step\n",
    "2. Intialize the decoder using $h^{enc}_T$ and run the decoder without any inputs\n",
    "\n",
    "In this exercise we follow the first approach because it's easier to implement. To do this need to create a lasagne layer that takes $h^{enc}_T$ and repeat it *N_decode_step* times. Below is an implementation of the RepeatLayer. You don't need to know the exact way it works, however make sure that you understand that it takes an input of size *(Batch_size x num_units)* and produces an output of size *(Batch_size x n_decode_steps x num_units)*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RepeatLayer(lasagne.layers.Layer):\n",
    "    def __init__(self, incoming, n, **kwargs):\n",
    "        '''\n",
    "        The input is expected to be a 2D tensor of shape \n",
    "        (num_batch, num_features). The input is repeated\n",
    "        n times such that the output will be \n",
    "        (num_batch, n, num_features)\n",
    "        '''\n",
    "        super(RepeatLayer, self).__init__(incoming, **kwargs)\n",
    "        self.n = n\n",
    "\n",
    "    def get_output_shape_for(self, input_shape):\n",
    "        return tuple([input_shape[0], self.n] + list(input_shape[1:]))\n",
    "\n",
    "    def get_output_for(self, input, **kwargs):\n",
    "        #repeat the input n times\n",
    "        tensors = [input]*self.n\n",
    "        stacked = theano.tensor.stack(*tensors)\n",
    "        dim = [1, 0] + range(2, input.ndim + 1)\n",
    "        return stacked.dimshuffle(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Data\n",
    "Since RNN models can be very slow to train on large datasets we will generate simpler training data for this exercise. The task for the RNN is simply to translate a string of letters spelling the numbers between 0-9 into the corresponding numbers i.e\n",
    "\n",
    "\"one two five\" --> \"125#\" (we use # as a special end-of-sequence character)\n",
    "\n",
    "To input the strings into the RNN model we translate the characters into a vector of integers using a simple translation table (i.e. 'h'->16, 'o'-> 17 etc). The code below prints a few input/output pairs using the *get_batch* function which randomly produces the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input types: int32 float32 int32 float32\n",
      "Number of valid characters: 27\n",
      "'0'=0,\t'1'=1,\t'2'=2,\t'3'=3,\t'4'=4,\t'5'=5,\t'6'=6,\t'7'=7,\t'8'=8,\t'9'=9,\t'#'=10,\t' '=11,\t'e'=12,\t'g'=13,\t'f'=14,\t'i'=15,\t'h'=16,\t'o'=17,\t'n'=18,\t's'=19,\t'r'=20,\t'u'=21,\t't'=22,\t'w'=23,\t'v'=24,\t'x'=25,\t'z'=26,\t\n",
      "None\n",
      "Stop character = #\n",
      "\n",
      "SAMPLE 0\n",
      "TEXT INPUTS:\t\tone zero\n",
      "TEXT TARGETS:\t\t10#\n",
      "ENCODED INPUTS:\t\t[17 18 12 11 26 12 20 17  0]\n",
      "MASK INPUTS:\t\t[ 1.  1.  1.  1.  1.  1.  1.  1.  0.]\n",
      "ENCODED TARGETS:\t[ 1  0 10]\n",
      "MASK TARGETS:\t\t[ 1.  1.  1.]\n",
      "\n",
      "SAMPLE 1\n",
      "TEXT INPUTS:\t\tseven two\n",
      "TEXT TARGETS:\t\t72#\n",
      "ENCODED INPUTS:\t\t[19 12 24 12 18 11 22 23 17]\n",
      "MASK INPUTS:\t\t[ 1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "ENCODED TARGETS:\t[ 7  2 10]\n",
      "MASK TARGETS:\t\t[ 1.  1.  1.]\n",
      "\n",
      "SAMPLE 2\n",
      "TEXT INPUTS:\t\tseven\n",
      "TEXT TARGETS:\t\t7#\n",
      "ENCODED INPUTS:\t\t[19 12 24 12 18  0  0  0  0]\n",
      "MASK INPUTS:\t\t[ 1.  1.  1.  1.  1.  0.  0.  0.  0.]\n",
      "ENCODED TARGETS:\t[ 7 10  0]\n",
      "MASK TARGETS:\t\t[ 1.  1.  0.]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 3\n",
    "inputs, input_masks, targets, target_masks, text_inputs, text_targets = \\\n",
    "    get_batch(batch_size=batch_size,max_digits=2,min_digits=1)\n",
    "\n",
    "print \"input types:\", inputs.dtype,  input_masks.dtype, targets.dtype, target_masks.dtype\n",
    "print print_valid_characters()\n",
    "print \"Stop character = #\"\n",
    "\n",
    "for i in range(batch_size):\n",
    "    print \"\\nSAMPLE\",i\n",
    "    print \"TEXT INPUTS:\\t\\t\", text_inputs[i]\n",
    "    print \"TEXT TARGETS:\\t\\t\", text_targets[i]\n",
    "    print \"ENCODED INPUTS:\\t\\t\", inputs[i]\n",
    "    print \"MASK INPUTS:\\t\\t\", input_masks[i]\n",
    "    print \"ENCODED TARGETS:\\t\", targets[i]\n",
    "    print \"MASK TARGETS:\\t\\t\", target_masks[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Decoder model setup\n",
    "Below is the Lasagne model implementation. We use an embedding layer to map from integer to multinomial vector representation.\n",
    "\n",
    "Note that the layer has a lot of print statements which we used for debugging during setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "(100, 20)\n",
      "(100, 20, 27)\n",
      "(100, 20, 10)\n",
      "(100, 10)\n",
      "Repeat layer\n",
      "(100, 21, 10)\n",
      "(100, 21, 10)\n",
      "(2100, 10)\n",
      "(2100, 11)\n",
      "(100, 21, 11)\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_UNITS_ENC = 10\n",
    "NUM_UNITS_DEC = 10\n",
    "MAX_DIGITS = 20 \n",
    "MIN_DIGITS = MAX_DIGITS #currently only support for same length outputs - we'll leave it for an exercise to add support for varying length targets\n",
    "NUM_INPUTS = 27\n",
    "NUM_OUTPUTS = 11 #(0-9 + '#')\n",
    "\n",
    "\n",
    "#symbolic theano variables. Note that we are using imatrix for X since it goes into the embedding layer\n",
    "x_sym = T.imatrix()\n",
    "y_sym = T.imatrix()\n",
    "xmask_sym = T.matrix()\n",
    "\n",
    "#dummy data to test implementation - We advise to check the output-dimensions of all layers.\n",
    "#One way to do this in lasagne/theano is to forward pass some data through the model and \n",
    "#check the output dimensions of these.\n",
    "#Create some random testdata\n",
    "X = np.random.randint(0,10,size=(BATCH_SIZE,MIN_DIGITS)).astype('int32')\n",
    "Xmask = np.ones((BATCH_SIZE,MIN_DIGITS)).astype('float32')\n",
    "\n",
    "print(type(X))\n",
    "print(X.shape)\n",
    "\n",
    "##### ENCODER START #####\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "#Here we'll remove the trainable parameters from the embeding layer to constrain \n",
    "#it to a simple \"one-hot-encoding\". You can experiment with removing this line\n",
    "l_emb.params[l_emb.W].remove('trainable') \n",
    "#forward pass some data throug the inputlayer-embedding layer and print the output shape\n",
    "print lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).eval({x_sym: X}).shape\n",
    "\n",
    "l_mask_enc = lasagne.layers.InputLayer((None, None))\n",
    "l_enc = lasagne.layers.GRULayer(l_emb, num_units=NUM_UNITS_ENC, name='GRUEncoder', mask_input=l_mask_enc)\n",
    "print lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "# slice last index of dimension 1\n",
    "l_last_hid = lasagne.layers.SliceLayer(l_enc, indices=-1, axis=1)\n",
    "print lasagne.layers.get_output(l_last_hid, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "##### END OF ENCODER######\n",
    "\n",
    "\n",
    "##### START OF DECODER######\n",
    "l_in_rep = RepeatLayer(l_last_hid, n=MAX_DIGITS+1) #we add one to allow space for the end of sequence character\n",
    "print(\"Repeat layer\")\n",
    "print lasagne.layers.get_output(l_in_rep, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "l_dec = lasagne.layers.GRULayer(l_in_rep, num_units=NUM_UNITS_DEC, name='GRUDecoder')\n",
    "print lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "\n",
    "# We need to do some reshape voodo to connect a softmax layer to the decoder.\n",
    "# See http://lasagne.readthedocs.org/en/latest/modules/layers/recurrent.html#examples \n",
    "# In short this line changes the shape from \n",
    "# (batch_size, decode_len, num_dec_units) -> (batch_size*decodelen,num_dec_units). \n",
    "# We need to do this since the softmax is applied to the last dimension and we want to \n",
    "# softmax the output at each position individually\n",
    "l_reshape = lasagne.layers.ReshapeLayer(l_dec, (-1, [2]))\n",
    "print lasagne.layers.get_output(l_reshape, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "l_softmax = lasagne.layers.DenseLayer(l_reshape, num_units=NUM_OUTPUTS, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                      name='SoftmaxOutput')\n",
    "print lasagne.layers.get_output(l_softmax, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "\n",
    "# reshape back to 3d format (batch_size, decode_len, num_dec_units). Here we tied the batch size to the shape of the symbolic variable for X allowing \n",
    "#us to use different batch sizes in the model.\n",
    "l_out = lasagne.layers.ReshapeLayer(l_softmax, (x_sym.shape[0], -1, NUM_OUTPUTS))\n",
    "print lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "###END OF DECODER######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the cost function and theano functions\n",
    "The targets are categorical, hence we use cross entropy error. We use the Adam optimizer but you\n",
    "can experiment with the different optimizers implemented in [Lasagne](http://lasagne.readthedocs.org/en/latest/modules/updates.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Model Parameters\n",
      "----------------------------------------\n",
      "GRUEncoder.W_in_to_updategate (27, 10)\n",
      "GRUEncoder.W_hid_to_updategate (10, 10)\n",
      "GRUEncoder.b_updategate (10,)\n",
      "GRUEncoder.W_in_to_resetgate (27, 10)\n",
      "GRUEncoder.W_hid_to_resetgate (10, 10)\n",
      "GRUEncoder.b_resetgate (10,)\n",
      "GRUEncoder.W_in_to_hidden_update (27, 10)\n",
      "GRUEncoder.W_hid_to_hidden_update (10, 10)\n",
      "GRUEncoder.b_hidden_update (10,)\n",
      "GRUDecoder.W_in_to_updategate (10, 10)\n",
      "GRUDecoder.W_hid_to_updategate (10, 10)\n",
      "GRUDecoder.b_updategate (10,)\n",
      "GRUDecoder.W_in_to_resetgate (10, 10)\n",
      "GRUDecoder.W_hid_to_resetgate (10, 10)\n",
      "GRUDecoder.b_resetgate (10,)\n",
      "GRUDecoder.W_in_to_hidden_update (10, 10)\n",
      "GRUDecoder.W_hid_to_hidden_update (10, 10)\n",
      "GRUDecoder.b_hidden_update (10,)\n",
      "SoftmaxOutput.W (10, 11)\n",
      "SoftmaxOutput.b (11,)\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "output_decoder_train = lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, \n",
    "                                                deterministic=False)\n",
    "\n",
    "#cost function\n",
    "total_cost = T.nnet.categorical_crossentropy(\n",
    "    T.reshape(output_decoder_train, (-1, NUM_OUTPUTS)), y_sym.flatten())\n",
    "mean_cost = T.mean(total_cost)\n",
    "#accuracy function\n",
    "argmax = T.argmax(output_decoder_train,axis=-1)\n",
    "eq = T.eq(argmax,y_sym)\n",
    "acc = T.mean(eq)  # gives float64 because eq is uint8, T.cast(eq, 'float32') will fix that...\n",
    "\n",
    "#Get parameters of both encoder and decoder\n",
    "all_parameters = lasagne.layers.get_all_params([l_out], trainable=True)\n",
    "\n",
    "print \"Trainable Model Parameters\"\n",
    "print \"-\"*40\n",
    "for param in all_parameters:\n",
    "    print param, param.get_value().shape\n",
    "print \"-\"*40\n",
    "\n",
    "#add grad clipping to avoid exploding gradients\n",
    "all_grads = [T.clip(g,-3,3) for g in T.grad(mean_cost, all_parameters)]\n",
    "all_grads = lasagne.updates.total_norm_constraint(all_grads,3)\n",
    "\n",
    "#Compile Theano functions.\n",
    "updates = lasagne.updates.adam(all_grads, all_parameters, learning_rate=0.005)\n",
    "train_func = theano.function([x_sym, y_sym, xmask_sym], [mean_cost, acc, output_decoder_train, argmax, eq], updates=updates)\n",
    "#since we don't have any stochasticity in the network we will just use the training graph without any updates given\n",
    "test_func = theano.function([x_sym, y_sym, xmask_sym], [acc, output_decoder_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Xval (5000, 111)\n",
      "Yval (5000, 21)\n"
     ]
    }
   ],
   "source": [
    "#Generate validation data\n",
    "Xval, Xmask_val, Yval, Ymask_val, text_inputs_val, text_targets_val = \\\n",
    "    get_batch(batch_size=5000, max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "print \"Xval\", Xval.shape\n",
    "print \"Yval\", Yval.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n",
      "Output shape:\n",
      "(100, 21, 11)\n",
      "Argmax shape:\n",
      "(100, 21)\n",
      "Eq shape:\n",
      "(100, 21)\n",
      "Y shape:\n",
      "(100, 21)\n"
     ]
    }
   ],
   "source": [
    "val_interval = 5000\n",
    "samples_to_process = 3e5\n",
    "samples_processed = 0\n",
    "\n",
    "val_samples = []\n",
    "costs, accs = [], []\n",
    "plt.figure()\n",
    "try:\n",
    "    while samples_processed < samples_to_process:\n",
    "        x_, x_masks_, ys_, y_masks_, _, _ = \\\n",
    "            get_batch(batch_size=BATCH_SIZE,max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "        print(\"Y shape:\")\n",
    "        print(ys_.shape)\n",
    "#         print(ys_.flatten().shape)\n",
    "        batch_cost, batch_acc, batch_output, batch_argmax, batch_eq = train_func(x_, ys_, x_masks_)\n",
    "        print(\"Output shape:\")\n",
    "        print(batch_output.shape)\n",
    "        print(\"Argmax shape:\")\n",
    "        print(batch_argmax.shape)\n",
    "        print(\"Eq shape:\")\n",
    "        print(batch_eq.shape)\n",
    "        costs += [batch_cost]\n",
    "        samples_processed += BATCH_SIZE\n",
    "        #validation data\n",
    "        if samples_processed % val_interval == 0:\n",
    "            #print \"validating\"\n",
    "            val_acc, val_output = test_func(Xval, Yval, Xmask_val)\n",
    "            val_samples += [samples_processed]\n",
    "            accs += [val_acc]\n",
    "            plt.plot(val_samples,accs)\n",
    "            plt.ylabel('Validation Accuracy', fontsize=15)\n",
    "            plt.xlabel('Processed samples', fontsize=15)\n",
    "            plt.title('', fontsize=20)\n",
    "            plt.grid('on')\n",
    "            plt.savefig(\"out.png\")\n",
    "            display.display(display.Image(filename=\"out.png\"))\n",
    "            display.clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "/* Put everything inside the global mpl namespace */\n",
       "window.mpl = {};\n",
       "\n",
       "mpl.get_websocket_type = function() {\n",
       "    if (typeof(WebSocket) !== 'undefined') {\n",
       "        return WebSocket;\n",
       "    } else if (typeof(MozWebSocket) !== 'undefined') {\n",
       "        return MozWebSocket;\n",
       "    } else {\n",
       "        alert('Your browser does not have WebSocket support.' +\n",
       "              'Please try Chrome, Safari or Firefox â‰¥ 6. ' +\n",
       "              'Firefox 4 and 5 are also supported but you ' +\n",
       "              'have to enable WebSockets in about:config.');\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure = function(figure_id, websocket, ondownload, parent_element) {\n",
       "    this.id = figure_id;\n",
       "\n",
       "    this.ws = websocket;\n",
       "\n",
       "    this.supports_binary = (this.ws.binaryType != undefined);\n",
       "\n",
       "    if (!this.supports_binary) {\n",
       "        var warnings = document.getElementById(\"mpl-warnings\");\n",
       "        if (warnings) {\n",
       "            warnings.style.display = 'block';\n",
       "            warnings.textContent = (\n",
       "                \"This browser does not support binary websocket messages. \" +\n",
       "                    \"Performance may be slow.\");\n",
       "        }\n",
       "    }\n",
       "\n",
       "    this.imageObj = new Image();\n",
       "\n",
       "    this.context = undefined;\n",
       "    this.message = undefined;\n",
       "    this.canvas = undefined;\n",
       "    this.rubberband_canvas = undefined;\n",
       "    this.rubberband_context = undefined;\n",
       "    this.format_dropdown = undefined;\n",
       "\n",
       "    this.image_mode = 'full';\n",
       "\n",
       "    this.root = $('<div/>');\n",
       "    this._root_extra_style(this.root)\n",
       "    this.root.attr('style', 'display: inline-block');\n",
       "\n",
       "    $(parent_element).append(this.root);\n",
       "\n",
       "    this._init_header(this);\n",
       "    this._init_canvas(this);\n",
       "    this._init_toolbar(this);\n",
       "\n",
       "    var fig = this;\n",
       "\n",
       "    this.waiting = false;\n",
       "\n",
       "    this.ws.onopen =  function () {\n",
       "            fig.send_message(\"supports_binary\", {value: fig.supports_binary});\n",
       "            fig.send_message(\"send_image_mode\", {});\n",
       "            fig.send_message(\"refresh\", {});\n",
       "        }\n",
       "\n",
       "    this.imageObj.onload = function() {\n",
       "            if (fig.image_mode == 'full') {\n",
       "                // Full images could contain transparency (where diff images\n",
       "                // almost always do), so we need to clear the canvas so that\n",
       "                // there is no ghosting.\n",
       "                fig.context.clearRect(0, 0, fig.canvas.width, fig.canvas.height);\n",
       "            }\n",
       "            fig.context.drawImage(fig.imageObj, 0, 0);\n",
       "        };\n",
       "\n",
       "    this.imageObj.onunload = function() {\n",
       "        this.ws.close();\n",
       "    }\n",
       "\n",
       "    this.ws.onmessage = this._make_on_message_function(this);\n",
       "\n",
       "    this.ondownload = ondownload;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_header = function() {\n",
       "    var titlebar = $(\n",
       "        '<div class=\"ui-dialog-titlebar ui-widget-header ui-corner-all ' +\n",
       "        'ui-helper-clearfix\"/>');\n",
       "    var titletext = $(\n",
       "        '<div class=\"ui-dialog-title\" style=\"width: 100%; ' +\n",
       "        'text-align: center; padding: 3px;\"/>');\n",
       "    titlebar.append(titletext)\n",
       "    this.root.append(titlebar);\n",
       "    this.header = titletext[0];\n",
       "}\n",
       "\n",
       "\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(canvas_div) {\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_canvas = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var canvas_div = $('<div/>');\n",
       "\n",
       "    canvas_div.attr('style', 'position: relative; clear: both; outline: 0');\n",
       "\n",
       "    function canvas_keyboard_event(event) {\n",
       "        return fig.key_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    canvas_div.keydown('key_press', canvas_keyboard_event);\n",
       "    canvas_div.keyup('key_release', canvas_keyboard_event);\n",
       "    this.canvas_div = canvas_div\n",
       "    this._canvas_extra_style(canvas_div)\n",
       "    this.root.append(canvas_div);\n",
       "\n",
       "    var canvas = $('<canvas/>');\n",
       "    canvas.addClass('mpl-canvas');\n",
       "    canvas.attr('style', \"left: 0; top: 0; z-index: 0; outline: 0\")\n",
       "\n",
       "    this.canvas = canvas[0];\n",
       "    this.context = canvas[0].getContext(\"2d\");\n",
       "\n",
       "    var rubberband = $('<canvas/>');\n",
       "    rubberband.attr('style', \"position: absolute; left: 0; top: 0; z-index: 1;\")\n",
       "\n",
       "    var pass_mouse_events = true;\n",
       "\n",
       "    canvas_div.resizable({\n",
       "        start: function(event, ui) {\n",
       "            pass_mouse_events = false;\n",
       "        },\n",
       "        resize: function(event, ui) {\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "        stop: function(event, ui) {\n",
       "            pass_mouse_events = true;\n",
       "            fig.request_resize(ui.size.width, ui.size.height);\n",
       "        },\n",
       "    });\n",
       "\n",
       "    function mouse_event_fn(event) {\n",
       "        if (pass_mouse_events)\n",
       "            return fig.mouse_event(event, event['data']);\n",
       "    }\n",
       "\n",
       "    rubberband.mousedown('button_press', mouse_event_fn);\n",
       "    rubberband.mouseup('button_release', mouse_event_fn);\n",
       "    // Throttle sequential mouse events to 1 every 20ms.\n",
       "    rubberband.mousemove('motion_notify', mouse_event_fn);\n",
       "\n",
       "    rubberband.mouseenter('figure_enter', mouse_event_fn);\n",
       "    rubberband.mouseleave('figure_leave', mouse_event_fn);\n",
       "\n",
       "    canvas_div.on(\"wheel\", function (event) {\n",
       "        event = event.originalEvent;\n",
       "        event['data'] = 'scroll'\n",
       "        if (event.deltaY < 0) {\n",
       "            event.step = 1;\n",
       "        } else {\n",
       "            event.step = -1;\n",
       "        }\n",
       "        mouse_event_fn(event);\n",
       "    });\n",
       "\n",
       "    canvas_div.append(canvas);\n",
       "    canvas_div.append(rubberband);\n",
       "\n",
       "    this.rubberband = rubberband;\n",
       "    this.rubberband_canvas = rubberband[0];\n",
       "    this.rubberband_context = rubberband[0].getContext(\"2d\");\n",
       "    this.rubberband_context.strokeStyle = \"#000000\";\n",
       "\n",
       "    this._resize_canvas = function(width, height) {\n",
       "        // Keep the size of the canvas, canvas container, and rubber band\n",
       "        // canvas in synch.\n",
       "        canvas_div.css('width', width)\n",
       "        canvas_div.css('height', height)\n",
       "\n",
       "        canvas.attr('width', width);\n",
       "        canvas.attr('height', height);\n",
       "\n",
       "        rubberband.attr('width', width);\n",
       "        rubberband.attr('height', height);\n",
       "    }\n",
       "\n",
       "    // Set the figure to an initial 600x600px, this will subsequently be updated\n",
       "    // upon first draw.\n",
       "    this._resize_canvas(600, 600);\n",
       "\n",
       "    // Disable right mouse context menu.\n",
       "    $(this.rubberband_canvas).bind(\"contextmenu\",function(e){\n",
       "        return false;\n",
       "    });\n",
       "\n",
       "    function set_focus () {\n",
       "        canvas.focus();\n",
       "        canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    window.setTimeout(set_focus, 100);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items) {\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) {\n",
       "            // put a spacer in here.\n",
       "            continue;\n",
       "        }\n",
       "        var button = $('<button/>');\n",
       "        button.addClass('ui-button ui-widget ui-state-default ui-corner-all ' +\n",
       "                        'ui-button-icon-only');\n",
       "        button.attr('role', 'button');\n",
       "        button.attr('aria-disabled', 'false');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "\n",
       "        var icon_img = $('<span/>');\n",
       "        icon_img.addClass('ui-button-icon-primary ui-icon');\n",
       "        icon_img.addClass(image);\n",
       "        icon_img.addClass('ui-corner-all');\n",
       "\n",
       "        var tooltip_span = $('<span/>');\n",
       "        tooltip_span.addClass('ui-button-text');\n",
       "        tooltip_span.html(tooltip);\n",
       "\n",
       "        button.append(icon_img);\n",
       "        button.append(tooltip_span);\n",
       "\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    var fmt_picker_span = $('<span/>');\n",
       "\n",
       "    var fmt_picker = $('<select/>');\n",
       "    fmt_picker.addClass('mpl-toolbar-option ui-widget ui-widget-content');\n",
       "    fmt_picker_span.append(fmt_picker);\n",
       "    nav_element.append(fmt_picker_span);\n",
       "    this.format_dropdown = fmt_picker[0];\n",
       "\n",
       "    for (var ind in mpl.extensions) {\n",
       "        var fmt = mpl.extensions[ind];\n",
       "        var option = $(\n",
       "            '<option/>', {selected: fmt === mpl.default_extension}).html(fmt);\n",
       "        fmt_picker.append(option)\n",
       "    }\n",
       "\n",
       "    // Add hover states to the ui-buttons\n",
       "    $( \".ui-button\" ).hover(\n",
       "        function() { $(this).addClass(\"ui-state-hover\");},\n",
       "        function() { $(this).removeClass(\"ui-state-hover\");}\n",
       "    );\n",
       "\n",
       "    var status_bar = $('<span class=\"mpl-message\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.request_resize = function(x_pixels, y_pixels) {\n",
       "    // Request matplotlib to resize the figure. Matplotlib will then trigger a resize in the client,\n",
       "    // which will in turn request a refresh of the image.\n",
       "    this.send_message('resize', {'width': x_pixels, 'height': y_pixels});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_message = function(type, properties) {\n",
       "    properties['type'] = type;\n",
       "    properties['figure_id'] = this.id;\n",
       "    this.ws.send(JSON.stringify(properties));\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.send_draw_message = function() {\n",
       "    if (!this.waiting) {\n",
       "        this.waiting = true;\n",
       "        this.ws.send(JSON.stringify({type: \"draw\", figure_id: this.id}));\n",
       "    }\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    var format_dropdown = fig.format_dropdown;\n",
       "    var format = format_dropdown.options[format_dropdown.selectedIndex].value;\n",
       "    fig.ondownload(fig, format);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.figure.prototype.handle_resize = function(fig, msg) {\n",
       "    var size = msg['size'];\n",
       "    if (size[0] != fig.canvas.width || size[1] != fig.canvas.height) {\n",
       "        fig._resize_canvas(size[0], size[1]);\n",
       "        fig.send_message(\"refresh\", {});\n",
       "    };\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_rubberband = function(fig, msg) {\n",
       "    var x0 = msg['x0'];\n",
       "    var y0 = fig.canvas.height - msg['y0'];\n",
       "    var x1 = msg['x1'];\n",
       "    var y1 = fig.canvas.height - msg['y1'];\n",
       "    x0 = Math.floor(x0) + 0.5;\n",
       "    y0 = Math.floor(y0) + 0.5;\n",
       "    x1 = Math.floor(x1) + 0.5;\n",
       "    y1 = Math.floor(y1) + 0.5;\n",
       "    var min_x = Math.min(x0, x1);\n",
       "    var min_y = Math.min(y0, y1);\n",
       "    var width = Math.abs(x1 - x0);\n",
       "    var height = Math.abs(y1 - y0);\n",
       "\n",
       "    fig.rubberband_context.clearRect(\n",
       "        0, 0, fig.canvas.width, fig.canvas.height);\n",
       "\n",
       "    fig.rubberband_context.strokeRect(min_x, min_y, width, height);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_figure_label = function(fig, msg) {\n",
       "    // Updates the figure title.\n",
       "    fig.header.textContent = msg['label'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_cursor = function(fig, msg) {\n",
       "    var cursor = msg['cursor'];\n",
       "    switch(cursor)\n",
       "    {\n",
       "    case 0:\n",
       "        cursor = 'pointer';\n",
       "        break;\n",
       "    case 1:\n",
       "        cursor = 'default';\n",
       "        break;\n",
       "    case 2:\n",
       "        cursor = 'crosshair';\n",
       "        break;\n",
       "    case 3:\n",
       "        cursor = 'move';\n",
       "        break;\n",
       "    }\n",
       "    fig.rubberband_canvas.style.cursor = cursor;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_message = function(fig, msg) {\n",
       "    fig.message.textContent = msg['message'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_draw = function(fig, msg) {\n",
       "    // Request the server to send over a new figure.\n",
       "    fig.send_draw_message();\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_image_mode = function(fig, msg) {\n",
       "    fig.image_mode = msg['mode'];\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Called whenever the canvas gets updated.\n",
       "    this.send_message(\"ack\", {});\n",
       "}\n",
       "\n",
       "// A function to construct a web socket function for onmessage handling.\n",
       "// Called in the figure constructor.\n",
       "mpl.figure.prototype._make_on_message_function = function(fig) {\n",
       "    return function socket_on_message(evt) {\n",
       "        if (evt.data instanceof Blob) {\n",
       "            /* FIXME: We get \"Resource interpreted as Image but\n",
       "             * transferred with MIME type text/plain:\" errors on\n",
       "             * Chrome.  But how to set the MIME type?  It doesn't seem\n",
       "             * to be part of the websocket stream */\n",
       "            evt.data.type = \"image/png\";\n",
       "\n",
       "            /* Free the memory for the previous frames */\n",
       "            if (fig.imageObj.src) {\n",
       "                (window.URL || window.webkitURL).revokeObjectURL(\n",
       "                    fig.imageObj.src);\n",
       "            }\n",
       "\n",
       "            fig.imageObj.src = (window.URL || window.webkitURL).createObjectURL(\n",
       "                evt.data);\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "        else if (typeof evt.data === 'string' && evt.data.slice(0, 21) == \"data:image/png;base64\") {\n",
       "            fig.imageObj.src = evt.data;\n",
       "            fig.updated_canvas_event();\n",
       "            fig.waiting = false;\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        var msg = JSON.parse(evt.data);\n",
       "        var msg_type = msg['type'];\n",
       "\n",
       "        // Call the  \"handle_{type}\" callback, which takes\n",
       "        // the figure and JSON message as its only arguments.\n",
       "        try {\n",
       "            var callback = fig[\"handle_\" + msg_type];\n",
       "        } catch (e) {\n",
       "            console.log(\"No handler for the '\" + msg_type + \"' message type: \", msg);\n",
       "            return;\n",
       "        }\n",
       "\n",
       "        if (callback) {\n",
       "            try {\n",
       "                // console.log(\"Handling '\" + msg_type + \"' message: \", msg);\n",
       "                callback(fig, msg);\n",
       "            } catch (e) {\n",
       "                console.log(\"Exception inside the 'handler_\" + msg_type + \"' callback:\", e, e.stack, msg);\n",
       "            }\n",
       "        }\n",
       "    };\n",
       "}\n",
       "\n",
       "// from http://stackoverflow.com/questions/1114465/getting-mouse-location-in-canvas\n",
       "mpl.findpos = function(e) {\n",
       "    //this section is from http://www.quirksmode.org/js/events_properties.html\n",
       "    var targ;\n",
       "    if (!e)\n",
       "        e = window.event;\n",
       "    if (e.target)\n",
       "        targ = e.target;\n",
       "    else if (e.srcElement)\n",
       "        targ = e.srcElement;\n",
       "    if (targ.nodeType == 3) // defeat Safari bug\n",
       "        targ = targ.parentNode;\n",
       "\n",
       "    // jQuery normalizes the pageX and pageY\n",
       "    // pageX,Y are the mouse positions relative to the document\n",
       "    // offset() returns the position of the element relative to the document\n",
       "    var x = e.pageX - $(targ).offset().left;\n",
       "    var y = e.pageY - $(targ).offset().top;\n",
       "\n",
       "    return {\"x\": x, \"y\": y};\n",
       "};\n",
       "\n",
       "/*\n",
       " * return a copy of an object with only non-object keys\n",
       " * we need this to avoid circular references\n",
       " * http://stackoverflow.com/a/24161582/3208463\n",
       " */\n",
       "function simpleKeys (original) {\n",
       "  return Object.keys(original).reduce(function (obj, key) {\n",
       "    if (typeof original[key] !== 'object')\n",
       "        obj[key] = original[key]\n",
       "    return obj;\n",
       "  }, {});\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.mouse_event = function(event, name) {\n",
       "    var canvas_pos = mpl.findpos(event)\n",
       "\n",
       "    if (name === 'button_press')\n",
       "    {\n",
       "        this.canvas.focus();\n",
       "        this.canvas_div.focus();\n",
       "    }\n",
       "\n",
       "    var x = canvas_pos.x;\n",
       "    var y = canvas_pos.y;\n",
       "\n",
       "    this.send_message(name, {x: x, y: y, button: event.button,\n",
       "                             step: event.step,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "\n",
       "    /* This prevents the web browser from automatically changing to\n",
       "     * the text insertion cursor when the button is pressed.  We want\n",
       "     * to control all of the cursor setting manually through the\n",
       "     * 'cursor' event from matplotlib */\n",
       "    event.preventDefault();\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    // Handle any extra behaviour associated with a key event\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.key_event = function(event, name) {\n",
       "\n",
       "    // Prevent repeat events\n",
       "    if (name == 'key_press')\n",
       "    {\n",
       "        if (event.which === this._key)\n",
       "            return;\n",
       "        else\n",
       "            this._key = event.which;\n",
       "    }\n",
       "    if (name == 'key_release')\n",
       "        this._key = null;\n",
       "\n",
       "    var value = '';\n",
       "    if (event.ctrlKey && event.which != 17)\n",
       "        value += \"ctrl+\";\n",
       "    if (event.altKey && event.which != 18)\n",
       "        value += \"alt+\";\n",
       "    if (event.shiftKey && event.which != 16)\n",
       "        value += \"shift+\";\n",
       "\n",
       "    value += 'k';\n",
       "    value += event.which.toString();\n",
       "\n",
       "    this._key_event_extra(event, name);\n",
       "\n",
       "    this.send_message(name, {key: value,\n",
       "                             guiEvent: simpleKeys(event)});\n",
       "    return false;\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onclick = function(name) {\n",
       "    if (name == 'download') {\n",
       "        this.handle_save(this, null);\n",
       "    } else {\n",
       "        this.send_message(\"toolbar_button\", {name: name});\n",
       "    }\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.toolbar_button_onmouseover = function(tooltip) {\n",
       "    this.message.textContent = tooltip;\n",
       "};\n",
       "mpl.toolbar_items = [[\"Home\", \"Reset original view\", \"fa fa-home icon-home\", \"home\"], [\"Back\", \"Back to  previous view\", \"fa fa-arrow-left icon-arrow-left\", \"back\"], [\"Forward\", \"Forward to next view\", \"fa fa-arrow-right icon-arrow-right\", \"forward\"], [\"\", \"\", \"\", \"\"], [\"Pan\", \"Pan axes with left mouse, zoom with right\", \"fa fa-arrows icon-move\", \"pan\"], [\"Zoom\", \"Zoom to rectangle\", \"fa fa-square-o icon-check-empty\", \"zoom\"], [\"\", \"\", \"\", \"\"], [\"Download\", \"Download plot\", \"fa fa-floppy-o icon-save\", \"download\"]];\n",
       "\n",
       "mpl.extensions = [\"eps\", \"jpeg\", \"pdf\", \"png\", \"ps\", \"raw\", \"svg\", \"tif\"];\n",
       "\n",
       "mpl.default_extension = \"png\";var comm_websocket_adapter = function(comm) {\n",
       "    // Create a \"websocket\"-like object which calls the given IPython comm\n",
       "    // object with the appropriate methods. Currently this is a non binary\n",
       "    // socket, so there is still some room for performance tuning.\n",
       "    var ws = {};\n",
       "\n",
       "    ws.close = function() {\n",
       "        comm.close()\n",
       "    };\n",
       "    ws.send = function(m) {\n",
       "        //console.log('sending', m);\n",
       "        comm.send(m);\n",
       "    };\n",
       "    // Register the callback with on_msg.\n",
       "    comm.on_msg(function(msg) {\n",
       "        //console.log('receiving', msg['content']['data'], msg);\n",
       "        // Pass the mpl event to the overriden (by mpl) onmessage function.\n",
       "        ws.onmessage(msg['content']['data'])\n",
       "    });\n",
       "    return ws;\n",
       "}\n",
       "\n",
       "mpl.mpl_figure_comm = function(comm, msg) {\n",
       "    // This is the function which gets called when the mpl process\n",
       "    // starts-up an IPython Comm through the \"matplotlib\" channel.\n",
       "\n",
       "    var id = msg.content.data.id;\n",
       "    // Get hold of the div created by the display call when the Comm\n",
       "    // socket was opened in Python.\n",
       "    var element = $(\"#\" + id);\n",
       "    var ws_proxy = comm_websocket_adapter(comm)\n",
       "\n",
       "    function ondownload(figure, format) {\n",
       "        window.open(figure.imageObj.src);\n",
       "    }\n",
       "\n",
       "    var fig = new mpl.figure(id, ws_proxy,\n",
       "                           ondownload,\n",
       "                           element.get(0));\n",
       "\n",
       "    // Call onopen now - mpl needs it, as it is assuming we've passed it a real\n",
       "    // web socket which is closed, not our websocket->open comm proxy.\n",
       "    ws_proxy.onopen();\n",
       "\n",
       "    fig.parent_element = element.get(0);\n",
       "    fig.cell_info = mpl.find_output_cell(\"<div id='\" + id + \"'></div>\");\n",
       "    if (!fig.cell_info) {\n",
       "        console.error(\"Failed to find cell for figure\", id, fig);\n",
       "        return;\n",
       "    }\n",
       "\n",
       "    var output_index = fig.cell_info[2]\n",
       "    var cell = fig.cell_info[0];\n",
       "\n",
       "};\n",
       "\n",
       "mpl.figure.prototype.handle_close = function(fig, msg) {\n",
       "    fig.root.unbind('remove')\n",
       "\n",
       "    // Update the output cell to use the data from the current canvas.\n",
       "    fig.push_to_output();\n",
       "    var dataURL = fig.canvas.toDataURL();\n",
       "    // Re-enable the keyboard manager in IPython - without this line, in FF,\n",
       "    // the notebook keyboard shortcuts fail.\n",
       "    IPython.keyboard_manager.enable()\n",
       "    $(fig.parent_element).html('<img src=\"' + dataURL + '\">');\n",
       "    fig.close_ws(fig, msg);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.close_ws = function(fig, msg){\n",
       "    fig.send_message('closing', msg);\n",
       "    // fig.ws.close()\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.push_to_output = function(remove_interactive) {\n",
       "    // Turn the data on the canvas into data in the output cell.\n",
       "    var dataURL = this.canvas.toDataURL();\n",
       "    this.cell_info[1]['text/html'] = '<img src=\"' + dataURL + '\">';\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.updated_canvas_event = function() {\n",
       "    // Tell IPython that the notebook contents must change.\n",
       "    IPython.notebook.set_dirty(true);\n",
       "    this.send_message(\"ack\", {});\n",
       "    var fig = this;\n",
       "    // Wait a second, then push the new image to the DOM so\n",
       "    // that it is saved nicely (might be nice to debounce this).\n",
       "    setTimeout(function () { fig.push_to_output() }, 1000);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._init_toolbar = function() {\n",
       "    var fig = this;\n",
       "\n",
       "    var nav_element = $('<div/>')\n",
       "    nav_element.attr('style', 'width: 100%');\n",
       "    this.root.append(nav_element);\n",
       "\n",
       "    // Define a callback function for later on.\n",
       "    function toolbar_event(event) {\n",
       "        return fig.toolbar_button_onclick(event['data']);\n",
       "    }\n",
       "    function toolbar_mouse_event(event) {\n",
       "        return fig.toolbar_button_onmouseover(event['data']);\n",
       "    }\n",
       "\n",
       "    for(var toolbar_ind in mpl.toolbar_items){\n",
       "        var name = mpl.toolbar_items[toolbar_ind][0];\n",
       "        var tooltip = mpl.toolbar_items[toolbar_ind][1];\n",
       "        var image = mpl.toolbar_items[toolbar_ind][2];\n",
       "        var method_name = mpl.toolbar_items[toolbar_ind][3];\n",
       "\n",
       "        if (!name) { continue; };\n",
       "\n",
       "        var button = $('<button class=\"btn btn-default\" href=\"#\" title=\"' + name + '\"><i class=\"fa ' + image + ' fa-lg\"></i></button>');\n",
       "        button.click(method_name, toolbar_event);\n",
       "        button.mouseover(tooltip, toolbar_mouse_event);\n",
       "        nav_element.append(button);\n",
       "    }\n",
       "\n",
       "    // Add the status bar.\n",
       "    var status_bar = $('<span class=\"mpl-message\" style=\"text-align:right; float: right;\"/>');\n",
       "    nav_element.append(status_bar);\n",
       "    this.message = status_bar[0];\n",
       "\n",
       "    // Add the close button to the window.\n",
       "    var buttongrp = $('<div class=\"btn-group inline pull-right\"></div>');\n",
       "    var button = $('<button class=\"btn btn-mini btn-primary\" href=\"#\" title=\"Stop Interaction\"><i class=\"fa fa-power-off icon-remove icon-large\"></i></button>');\n",
       "    button.click(function (evt) { fig.handle_close(fig, {}); } );\n",
       "    button.mouseover('Stop Interaction', toolbar_mouse_event);\n",
       "    buttongrp.append(button);\n",
       "    var titlebar = this.root.find($('.ui-dialog-titlebar'));\n",
       "    titlebar.prepend(buttongrp);\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._root_extra_style = function(el){\n",
       "    var fig = this\n",
       "    el.on(\"remove\", function(){\n",
       "\tfig.close_ws(fig, {});\n",
       "    });\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._canvas_extra_style = function(el){\n",
       "    // this is important to make the div 'focusable\n",
       "    el.attr('tabindex', 0)\n",
       "    // reach out to IPython and tell the keyboard manager to turn it's self\n",
       "    // off when our div gets focus\n",
       "\n",
       "    // location in version 3\n",
       "    if (IPython.notebook.keyboard_manager) {\n",
       "        IPython.notebook.keyboard_manager.register_events(el);\n",
       "    }\n",
       "    else {\n",
       "        // location in version 2\n",
       "        IPython.keyboard_manager.register_events(el);\n",
       "    }\n",
       "\n",
       "}\n",
       "\n",
       "mpl.figure.prototype._key_event_extra = function(event, name) {\n",
       "    var manager = IPython.notebook.keyboard_manager;\n",
       "    if (!manager)\n",
       "        manager = IPython.keyboard_manager;\n",
       "\n",
       "    // Check for shift+enter\n",
       "    if (event.shiftKey && event.which == 13) {\n",
       "        this.canvas_div.blur();\n",
       "        // select the cell after this one\n",
       "        var index = IPython.notebook.find_cell_index(this.cell_info[0]);\n",
       "        IPython.notebook.select(index + 1);\n",
       "    }\n",
       "}\n",
       "\n",
       "mpl.figure.prototype.handle_save = function(fig, msg) {\n",
       "    fig.ondownload(fig, null);\n",
       "}\n",
       "\n",
       "\n",
       "mpl.find_output_cell = function(html_output) {\n",
       "    // Return the cell and output element which can be found *uniquely* in the notebook.\n",
       "    // Note - this is a bit hacky, but it is done because the \"notebook_saving.Notebook\"\n",
       "    // IPython event is triggered only after the cells have been serialised, which for\n",
       "    // our purposes (turning an active figure into a static one), is too late.\n",
       "    var cells = IPython.notebook.get_cells();\n",
       "    var ncells = cells.length;\n",
       "    for (var i=0; i<ncells; i++) {\n",
       "        var cell = cells[i];\n",
       "        if (cell.cell_type === 'code'){\n",
       "            for (var j=0; j<cell.output_area.outputs.length; j++) {\n",
       "                var data = cell.output_area.outputs[j];\n",
       "                if (data.data) {\n",
       "                    // IPython >= 3 moved mimebundle to data attribute of output\n",
       "                    data = data.data;\n",
       "                }\n",
       "                if (data['text/html'] == html_output) {\n",
       "                    return [cell, data, j];\n",
       "                }\n",
       "            }\n",
       "        }\n",
       "    }\n",
       "}\n",
       "\n",
       "// Register the function which deals with the matplotlib target/channel.\n",
       "// The kernel may be null if the page has been refreshed.\n",
       "if (IPython.notebook.kernel != null) {\n",
       "    IPython.notebook.kernel.comm_manager.register_target('matplotlib', mpl.mpl_figure_comm);\n",
       "}\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id='fbd34c96-c13d-4003-9f03-5a28291e7f75'></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot of validation accuracy for each target position\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(np.mean(np.argmax(val_output,axis=2)==Yval,axis=0))\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Target position', fontsize=15)\n",
    "#plt.title('', fontsize=20)\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "#why do the plots look like this? See exercise 4 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# plot training cost\n",
    "#plt.figure(figsize=(7,7))\n",
    "#plt.plot(costs)\n",
    "#plt.ylabel('Cost', fontsize=15)\n",
    "#plt.xlabel('Number of updates', fontsize=15)\n",
    "#plt.title('Training', fontsize=20)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT INPUTS:\t\tsix two four zero eight two one four zero seven five five nine one nine five eight seven eight seven\n",
      "TEXT TARGETS:\t\t62408214075591958787#\n",
      "RESULTS:\n",
      "555555555555555555###\n"
     ]
    }
   ],
   "source": [
    "### Added to test the output\n",
    "batch_size = 1\n",
    "inputs, input_masks, targets, target_masks, text_inputs, text_targets = \\\n",
    "    get_batch(batch_size=batch_size,max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "    \n",
    "# test_func = theano.function([x_sym, y_sym, xmask_sym], [acc, output_decoder_train])\n",
    "    \n",
    "# Xval, Xmask_val, Yval, Ymask_val, text_inputs_val, text_targets_val = \\\n",
    "#     get_batch(batch_size=5000, max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "\n",
    "# print \"input types:\", inputs.dtype,  input_masks.dtype, targets.dtype, target_masks.dtype\n",
    "# print print_valid_characters()\n",
    "# print \"Stop character = #\"\n",
    "\n",
    "for i in range(batch_size):\n",
    "#     print \"\\nSAMPLE\",i\n",
    "    print \"TEXT INPUTS:\\t\\t\", text_inputs[i]\n",
    "    print \"TEXT TARGETS:\\t\\t\", text_targets[i]\n",
    "#     print \"ENCODED INPUTS:\\t\\t\", inputs[i]\n",
    "#     print \"MASK INPUTS:\\t\\t\", input_masks[i]\n",
    "#     print \"ENCODED TARGETS:\\t\", targets[i]\n",
    "#     print \"MASK TARGETS:\\t\\t\", target_masks[i]\n",
    "\n",
    "val_acc, val_output = test_func(inputs, targets, input_masks)\n",
    "\n",
    "print(\"RESULTS:\")\n",
    "\n",
    "prediction = \"\"\n",
    "for digit in val_output:\n",
    "    for out in digit:\n",
    "#         print(out)\n",
    "        idx = np.argmax(out)\n",
    "        if idx == NUM_OUTPUTS - 1:\n",
    "            idx = '#'\n",
    "        prediction += str(idx)\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises:\n",
    "1. Perform an explorative test of the network by inputting a defined input and evaulate the outputs.\n",
    "2. The model has two GRU networks. The ```GRUEncoder``` and the ```GRUDecoder```. A GRU is parameterized by the  ```{W_in_to_updategate, W_hid_to_updategate, b_updategate, W_in_to_resetgate, W_hid_to_resetgate, b_resetgate,\n",
    "W_in_to_hidden_update, W_hid_to_hidden_update,b_hidden_update}```. Try to explain the shape of ```W_in_to_updategate``` and ```hid_to_updategate```. Why are they different? You can find the equations for the gru at: [GRU](http://lasagne.readthedocs.io/en/latest/modules/layers/recurrent.html#lasagne.layers.GRULayer). \n",
    "3. The GRU unit is able to ignore the input and just copy the previous hidden state. In the beginning of training this might be desireable behavior, since it helps the model learn long range dependencies. You can make the model ignore the input by modifying initial bias values. What bias would you modify and how would you modify it? Again you'll need to refer to the GRU equations:  [GRU](http://lasagne.readthedocs.io/en/latest/modules/layers/recurrent.html#lasagne.layers.GRULayer).\n",
    "\n",
    "4. What is the final validation performance? Why do you think it is not better? Comment on the accuracy for each position in of the output symbols?\n",
    "\n",
    "5. Why do you think the validation performance looks more \"jig-saw\"-like compared to FFNN and CNN models?\n",
    "\n",
    "6. In the example we stack a softmax layer on top of a Recurrent layer. In the code snippet below explain how we can do that?\n",
    "\n",
    "# Answers:\n",
    "## 1) \n",
    "I just get a random example from get_batch with a batch size of 1, insted of hard-coding a single example (see just above). There seems to be a trend for the results, so it didn't seem necessary to use just one fixed input.\n",
    "\n",
    "What I see is that the network is pretty bad and has a tendency to predict the same digits several times in a row.\n",
    "\n",
    "## 2)\n",
    "They are weights for the input from the previous hidden layer, and for the recurrent layer at earlier time-steps respectively. As the number of inputs is different from the number of units in the recurrent layer, the shapes of the two weight-vectors are different.\n",
    "\n",
    "## 3)\n",
    "I would make $b_u$, used to calculate $u_t$, increadibly small. Since this adjusts the input to the sigmoid function, the result of the sigmoid operation will be ~0, which in turn results in the unit ignoring input from the previous layer (at current time) and using the values from the previous time-step.\n",
    "\n",
    "## 4)\n",
    "The accuracy is just above 15%, but goes to 100% for the last position, as it always gets the end-of-line character correct. I assume it is this bad because it has not properly learned when to use prior results and when to use new input, hence we see the same digit often being repeated in the output.\n",
    "\n",
    "## 5)\n",
    "I believe it is because of the GRU memory units, and the fact that they will at some point \"discard/forget\" a previous input in favor of a new input from the current time-step. Even though they are not discrete units that use one value or the other, I imagine that these changes could result in jumps in the output.\n",
    "\n",
    "As I do not fully understand what the question is referring to I will just note that the jaggedness of the validation graph we see while training comes from the fact that we only plot it for every 5000 training examples, running on a total of 300000 exemples, many more than for previous networks we have trained.\n",
    "\n",
    "## 6)\n",
    "See comments below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l_input_ (16, 140, 40)\n",
      "l_gru_ (16, 140, 10)\n",
      "l_reshape_ (2240, 10)\n",
      "l_softmax_ (2240, 11)\n",
      "l_softmax_seq_ (16, 140, 11)\n"
     ]
    }
   ],
   "source": [
    "### Store the dimensions of the recurrent layer to return to that shape later\n",
    "bs_, seqlen_, numinputs_ = 16, 140, 40 \n",
    "l_input_ = lasagne.layers.InputLayer((bs_, seqlen_, numinputs_))\n",
    "l_gru_ = lasagne.layers.GRULayer(l_input_, num_units=10)\n",
    "### We reshape/flatten the recurrent layer to simulate a standard dense layer.\n",
    "### We do this to allow the softmax layer access to the activations from the GRU layer\n",
    "l_reshape_ = lasagne.layers.ReshapeLayer(l_gru_, (-1, [2])) # the [2] tells lasagne to use the dim of the 2. \n",
    "                                                            # dim of the input here. -1 is a wildcard\n",
    "\n",
    "### We map from 10 to 11 units to include the end of input character. \n",
    "### The 10 first units will map directly to the input, and the last that is not needed will have a high \n",
    "### activation when the others are low due to softmax summing to 1, which makes it represent end-of-sequence.\n",
    "l_softmax_ = lasagne.layers.DenseLayer(l_reshape_, num_units=11, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax)\n",
    "### Reshape to return to recurrent structure\n",
    "l_softmax_seq_ = lasagne.layers.ReshapeLayer(l_softmax_,(bs_, seqlen_, -1))\n",
    "print \"l_input_\", l_input_.output_shape\n",
    "print \"l_gru_\", l_gru_.output_shape\n",
    "print \"l_reshape_\", l_reshape_.output_shape\n",
    "print \"l_softmax_\", l_softmax_.output_shape\n",
    "print \"l_softmax_seq_\", l_softmax_seq_.output_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Optional: If you are interested in doing sentiment analysis on tweets, i.e classification as positive or negative. Use RNN to read over the twitter seqeuence and use the last hidden state to do the classification. How can you modify the small network above to only output binary classification? Hints: Look at the SliceLayer or the GRU docs...\n",
    "7. Optional: Bidirectional Encoder, In Lasagne, bidirectional RNNs are implementated by running a forward model and a backward model separately and then concatenating them before parsing them to the next layer. You can experiment with using a different merging layer than concat e.g. sum or multiplication see [lasagne merge layers [lasagne merge layers](http://lasagne.readthedocs.org/en/latest/modules/layers/merge.html).\n",
    "```\n",
    "l_rec_fwd = lasagne.layers.GRULayer(...,backwards=False)\n",
    "l_rec_bwd = lasagne.layers.GRULayer(...,backwards=True)\n",
    "l_rec = lasagne.layers.ConcatLayer([l_rec_fwd, l_rec_bwd], axis=2))\n",
    "```\n",
    "8. Optional: Add support for different lengths of targets (hint: add the target_mask to the cost function and only calculate the cost for the non-masked targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Decoder (LSTM)\n",
    "Selective attention for recurrent neural networks have recently attracted a lot of interest. These methods let the Decoder model selectively focus on which sub-sequence of the encoder sequence it will use for each decoded output symbol. This relieves the encoder from having to compress the input sequence into a fixed size vector representation. Secondly, we can investigate which part of the input that the decoder network emphazises. Below we'll implement an LSTM-decoder with selective attention and show that it significantly improves the performance of the toy translation task.\n",
    "\n",
    "The attention paper is found here: https://arxiv.org/pdf/1409.0473v7.pdf.\n",
    "\n",
    "The principles of the attention model are simple. \n",
    "\n",
    "1. Use the encoder to get the hidden represention $\\{h^1_e, ...h^n_e\\}$ for each position in the input sequence. \n",
    "2. For timestep $t$ in the decoder $m = 1...n$ : $a_m = f(h^m_e, h^d_t)$. Where f is a function returning a scalar value.\n",
    "3. You can then normalize the sequence of scalars $\\{a_1, ... a_n\\}$ to get probablities $\\{p_1, ... p_n\\}$.\n",
    "4. Weigh each $h^e_t$ by its probablity $p_t$ and sum to get $h_{in}$.\n",
    "5. Use $h_{in}$ as an additional input to the decoder. $h_{in}$ is recalculated each time the decoder is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20, 27)\n",
      "(100, 20, 10)\n",
      "(100, 21, 10)\n",
      "(100, 21, 11)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from decoder_attention import LSTMAttentionDecodeFeedbackLayer\n",
    "\n",
    "# you can acces the attetion weights alpha by adding l_dec.alpha \n",
    "# to the output variables in the theano function\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "NUM_UNITS_ENC = 10\n",
    "NUM_UNITS_DEC = 10\n",
    "MAX_DIGITS = 20 \n",
    "MIN_DIGITS = MAX_DIGITS #currently only support for same length outputs - we'll leave it for an exercise to add support for varying length targets\n",
    "NUM_INPUTS = 27\n",
    "NUM_OUTPUTS = 11 #(0-9 + '#')\n",
    "\n",
    "\n",
    "x_sym = T.imatrix()\n",
    "y_sym = T.imatrix()\n",
    "xmask_sym = T.matrix()\n",
    "    \n",
    "\n",
    "#dummy data to test implementation\n",
    "#X = np.random.randint(0,10,size=(BATCH_SIZE,15)).astype('int32')\n",
    "#Xmask = np.ones((BATCH_SIZE,NUM_INPUTS)).astype('float32')\n",
    "\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "##### ENCODER START #####\n",
    "l_in = lasagne.layers.InputLayer((None, None))\n",
    "l_emb = lasagne.layers.EmbeddingLayer(l_in, NUM_INPUTS, NUM_INPUTS, \n",
    "                                      W=np.eye(NUM_INPUTS,dtype='float32'),\n",
    "                                      name='Embedding')\n",
    "#Here we'll remove the trainable parameters from the embeding layer to constrain \n",
    "#it to a simple \"one-hot-encoding\". You can experiment with removing this line\n",
    "l_emb.params[l_emb.W].remove('trainable') \n",
    "print lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).eval(\n",
    "    {x_sym: X}).shape\n",
    "T.grad(lasagne.layers.get_output(l_emb, inputs={l_in: x_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_emb, trainable=True))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "l_mask_enc = lasagne.layers.InputLayer((None, None))\n",
    "l_enc = lasagne.layers.GRULayer(l_emb, num_units=NUM_UNITS_ENC, name='GRUEncoder', mask_input=l_mask_enc)\n",
    "print lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_enc, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_enc, trainable=True))\n",
    "####END OF ENCODER######\n",
    "\n",
    "\n",
    "####START OF DECODER######\n",
    "#note that the decoder have its own input layer, we'll use that to plug in the output \n",
    "#from the encoder later\n",
    "l_dec = LSTMAttentionDecodeFeedbackLayer(l_enc,\n",
    "                                        num_units=NUM_UNITS_DEC, \n",
    "                                        aln_num_units=20,\n",
    "                                        n_decodesteps=MAX_DIGITS+1,\n",
    "                                        name='LSTMDecoder')\n",
    "print lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_dec, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_dec, trainable=True))\n",
    "\n",
    "# We need to do some reshape voodo to connect a softmax layer to the decoder.\n",
    "# See http://lasagne.readthedocs.org/en/latest/modules/layers/recurrent.html#examples \n",
    "l_reshape = lasagne.layers.ReshapeLayer(l_dec, (-1, [2]))\n",
    "l_softmax = lasagne.layers.DenseLayer(l_reshape, num_units=NUM_OUTPUTS, \n",
    "                                      nonlinearity=lasagne.nonlinearities.softmax,\n",
    "                                      name='SoftmaxOutput')\n",
    "# print lasagne.layers.get_output(l_softmax, x_sym).eval({x_sym: X}).shape\n",
    "# reshape back to 3d format (here we tied the batch size to the shape of the symbolic variable for X allowing \n",
    "#us to use different batch sizes in the model)\n",
    "l_out = lasagne.layers.ReshapeLayer(l_softmax, (x_sym.shape[0], -1, NUM_OUTPUTS))\n",
    "print lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, deterministic=False).eval(\n",
    "    {x_sym: X, xmask_sym: Xmask}).shape\n",
    "T.grad(lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}).sum(), \n",
    "       lasagne.layers.get_all_params(l_dec, trainable=True))\n",
    "\n",
    "print \"\"\n",
    "###END OF DECODER######\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Generate some validation data\n",
    "Xval, Xmask_val, Yval, Ymask_val, text_inputs_val, text_targets_val = \\\n",
    "    get_batch(batch_size=5000, max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable Model Parameters\n",
      "----------------------------------------\n",
      "GRUEncoder.W_in_to_updategate (27, 10)\n",
      "GRUEncoder.W_hid_to_updategate (10, 10)\n",
      "GRUEncoder.b_updategate (10,)\n",
      "GRUEncoder.W_in_to_resetgate (27, 10)\n",
      "GRUEncoder.W_hid_to_resetgate (10, 10)\n",
      "GRUEncoder.b_resetgate (10,)\n",
      "GRUEncoder.W_in_to_hidden_update (27, 10)\n",
      "GRUEncoder.W_hid_to_hidden_update (10, 10)\n",
      "GRUEncoder.b_hidden_update (10,)\n",
      "LSTMDecoder.W_hid_to_ingate (10, 10)\n",
      "LSTMDecoder.b_ingate (10,)\n",
      "LSTMDecoder.W_hid_to_forgetgate (10, 10)\n",
      "LSTMDecoder.b_forgetgate (10,)\n",
      "LSTMDecoder.W_hid_to_cell (10, 10)\n",
      "LSTMDecoder.b_cell (10,)\n",
      "LSTMDecoder.W_hid_to_outgate (10, 10)\n",
      "LSTMDecoder.b_outgate (10,)\n",
      "LSTMDecoder.W_weightedhid_to_ingate (10, 10)\n",
      "LSTMDecoder.W_weightedhid_to_forgetgate (10, 10)\n",
      "LSTMDecoder.W_weightedhid_to_cell (10, 10)\n",
      "LSTMDecoder.W_weightedhid_to_outgate (10, 10)\n",
      "LSTMDecoder.W_cell_to_ingate (10,)\n",
      "LSTMDecoder.W_cell_to_forgetgate (10,)\n",
      "LSTMDecoder.W_cell_to_outgate (10,)\n",
      "LSTMDecoder.AlignSeqOutputLayer: (aln) W_a (10, 20)\n",
      "LSTMDecoder.AlignSeqOutputLayer: (aln) U_a (10, 20)\n",
      "LSTMDecoder.AlignSeqOutputLayer: v_a (20, 1)\n",
      "SoftmaxOutput.W (10, 11)\n",
      "SoftmaxOutput.b (11,)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR (theano.gof.opt): Optimization failure due to: local_reshape_dimshuffle\n",
      "ERROR (theano.gof.opt): node: Reshape{2}(InplaceDimShuffle{0,x}.0, <TensorType(int64, vector)>)\n",
      "ERROR (theano.gof.opt): TRACEBACK:\n",
      "ERROR (theano.gof.opt): Traceback (most recent call last):\n",
      "  File \"/home/nch/anaconda2/lib/python2.7/site-packages/theano/gof/opt.py\", line 1922, in process_node\n",
      "    replacements = lopt.transform(node)\n",
      "  File \"/home/nch/anaconda2/lib/python2.7/site-packages/theano/tensor/opt_uncanonicalize.py\", line 147, in local_reshape_dimshuffle\n",
      "    return [T.reshape(input_.owner.inputs[0], node.inputs[1])]\n",
      "  File \"/home/nch/anaconda2/lib/python2.7/site-packages/theano/tensor/basic.py\", line 4683, in reshape\n",
      "    \"argument to 'reshape' to avoid this problem.\" % newshape)\n",
      "ValueError: The length of the provided shape (<TensorType(int64, vector)>) cannot be automatically determined, so Theano is not able to know what the number of dimensions of the reshaped variable will be. You can provide the 'ndim' keyword argument to 'reshape' to avoid this problem.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#get output of encoder using X and Xmask as input\n",
    "output_decoder_train = lasagne.layers.get_output(l_out, inputs={l_in: x_sym, l_mask_enc: xmask_sym}, \n",
    "                                                 deterministic=False)\n",
    "\n",
    "#cost function\n",
    "total_cost = T.nnet.categorical_crossentropy(\n",
    "    T.reshape(output_decoder_train, (-1, NUM_OUTPUTS)), y_sym.flatten())\n",
    "mean_cost = T.mean(total_cost)\n",
    "#accuracy function\n",
    "acc = T.mean(T.eq(T.argmax(output_decoder_train,axis=-1),y_sym))\n",
    "\n",
    "#Get parameters of both encoder and decoder\n",
    "all_parameters = lasagne.layers.get_all_params(l_out, trainable=True)\n",
    "\n",
    "print \"Trainable Model Parameters\"\n",
    "print \"-\"*40\n",
    "for param in all_parameters:\n",
    "    print param, param.get_value().shape\n",
    "print \"-\"*40\n",
    "\n",
    "#add grad clipping to avoid exploding gradients\n",
    "all_grads = [T.clip(g,-3,3) for g in T.grad(mean_cost, all_parameters)]\n",
    "all_grads = lasagne.updates.total_norm_constraint(all_grads,3)\n",
    "\n",
    "#Compile Theano functions\n",
    "updates = lasagne.updates.adam(all_grads, all_parameters, learning_rate=0.005)\n",
    "train_func = theano.function([x_sym, y_sym, xmask_sym], [mean_cost, acc, output_decoder_train], updates=updates)\n",
    "#since we don't have any stochasticity in the network we will just use the training graph without any updates given\n",
    "test_func = theano.function([x_sym, y_sym, xmask_sym], [acc, output_decoder_train, l_dec.alpha])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGQCAYAAAByNR6YAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njlNiPMByHMdxHMcpMf8P+IA9sKKeiJEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_interval = 5000\n",
    "samples_to_process = 1.5e5\n",
    "samples_processed = 0\n",
    "val_samples = []\n",
    "costs, accs = [], []\n",
    "plt.figure()\n",
    "try:\n",
    "    while samples_processed < samples_to_process:\n",
    "        inputs, input_masks, targets, target_masks, _, _ = \\\n",
    "            get_batch(batch_size=BATCH_SIZE,max_digits=MAX_DIGITS,min_digits=MIN_DIGITS)\n",
    "        batch_cost, batch_acc, batch_output = train_func(inputs, targets, input_masks)\n",
    "        costs += [batch_cost]\n",
    "        samples_processed += BATCH_SIZE\n",
    "        if samples_processed % val_interval == 0:\n",
    "            #print \"validating\"\n",
    "            val_acc, val_output, alpha = test_func(Xval, Yval, Xmask_val)\n",
    "            val_samples += [samples_processed]\n",
    "            accs += [val_acc]\n",
    "            plt.plot(val_samples,accs)\n",
    "            plt.ylabel('', fontsize=15)\n",
    "            plt.xlabel('Processed samples', fontsize=15)\n",
    "            plt.title('Validation Accuracy', fontsize=20)\n",
    "            plt.grid('on')\n",
    "            plt.savefig(\"out.png\")\n",
    "            display.display(display.Image(filename=\"out.png\"))\n",
    "            display.clear_output(wait=True)\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#plot of validation accuracy for each target position\n",
    "plt.figure(figsize=(7,7))\n",
    "plt.plot(np.mean(np.argmax(val_output,axis=2)==Yval,axis=0))\n",
    "plt.ylabel('Accuracy', fontsize=15)\n",
    "plt.xlabel('Target position', fontsize=15)\n",
    "#plt.title('', fontsize=20)\n",
    "plt.grid('on')\n",
    "plt.show()\n",
    "#why do the plot look like this?\n",
    "### The network is still bad at predicting the later parts of the input.\n",
    "### This is because the input will diverge more and more from the learned attentions the further we get"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Plot of average attention weight as a function of the sequence position for each of \n",
    "#the 21 targets in the output sequence i.e. each line is the mean postion of the \n",
    "#attention for each target position.\n",
    "\n",
    "np.mean(alpha,axis=0).shape\n",
    "plt.figure()\n",
    "plt.plot(np.mean(alpha,axis=0).T)\n",
    "plt.ylabel('alpha', fontsize=15)\n",
    "plt.xlabel('Input Sequence position', fontsize=15)\n",
    "plt.title('Alpha weights', fontsize=20)\n",
    "plt.legend(map(str,range(1,22)), bbox_to_anchor=(1.125,1.0), fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Assignments for the attention decoder\n",
    "1. Explain what the alpha weights show. \n",
    "2. Why are the alpha curve for the first digit narrow and peaked while later digits have alpha curves that are wider and less peaked?\n",
    "3. Why is attention a good idea for this problem? Can you think of other problems where attention is a good choice?\n",
    "\n",
    "## Answers\n",
    "### 1)\n",
    "The alpha weights are a visualization of the attention given to calculate the $i$th output digit, based on how far you are in the input sequence. \n",
    "\n",
    "### 2)\n",
    "The first digit can only appear in the first part of the input sequence. It has a length within a fixed range (which depends on the number of letters used to spell each number used in the training data), and so we are always relatively sure where to find it, so we want to pay close attention to that part of the sequence for that digit. For each consecutive digit we become more unsure of the position interval the digit will appear in, and so we have to spread our attention out more to find it. This is of course because each digit takes up a varying part of the input sequence, so for each digit we process we offset the start of the next digit by more.\n",
    "\n",
    "### 3)\n",
    "Attention is a good idea for this problem because the network has to learn that the input consists of small chunks of data, which have to be interpreted separately. Attention greatly helps to learn in which areas of the inputs the borders between digits will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
